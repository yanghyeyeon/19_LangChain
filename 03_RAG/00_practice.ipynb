{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문서의 페이지수 : 25\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "\n",
    "# pyMuPDFLoader 객체 정의\n",
    "loader = PyMuPDFLoader(\"data/SPRi AI Brief_10월호_산업동향_F.pdf\")\n",
    "\n",
    "# 문서 로드\n",
    "docs = loader.load()\n",
    "\n",
    "print(f\"문서의 페이지수 : {len(docs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "분할된 청크의 수 : 61\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=800, chunk_overlap=100)\n",
    "\n",
    "split_documents = text_splitter.split_documents(docs)\n",
    "\n",
    "print(f\"분할된 청크의 수 : {len(split_documents)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embeddings = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "vectorstore = FAISS.from_documents(documents=split_documents, embedding=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. 정책/법제  \n",
      "2. 기업/산업 \n",
      "3. 기술/연구 \n",
      " 4. 인력/교육\n",
      "7\n",
      "메타의 AI 모델 ‘라마’, 다운로드 수 3억 5천만 회 달성하며 활발한 생태계 형성\n",
      "n 메타의 오픈소스 AI 모델 ‘라마’는 2023년 2월 출시 이래 다운로드 수 3억 5천만 건을 \n",
      "기록했으며, 허깅페이스에는 6만 개 이상의 라마 파생 모델이 존재\n",
      "n 액센추어, AT&T, 도어대시, 노무라, 줌을 비롯한 주요 기업들은 보고서 작성, 고객 관리, 개발 \n",
      "업무 지원 등 자체 목적에 맞게 라마를 미세 조정하여 활용\n",
      "KEY Contents\n",
      " \n",
      "£ 메타의 오픈소스 AI 모델 ‘라마’, 2023년 대비 다운로드 수 10배 이상 증가\n",
      "n 메타(Meta)가 2023년 2월 처음 출시한 AI 모델 ‘라마(Llama)’의 다운로드 수가 3억 5천만 건에 \n",
      "달하며 2023년 대비 다운로드 수가 10배 이상 증가했다고 발표 \n",
      "∙라마는 3.1 버전이 출시된 2024년 7월 한 달 동안 허깅페이스(Hugging Face)*에서 2천만 건 이상\n",
      "의 다운로드를 기록해 오픈소스 모델 제품군 중 선두를 차지\n",
      "* 머신러닝 모델을 구축, 배포, 훈련할 수 있도록 다양한 도구와 라이브러리를 제공하는 플랫폼\n",
      "∙AWS, 마이크로소프트(Microsoft) 등의 대형 클라우드 제공업체를 통한 라마의 월간 사용량은 2024년 \n",
      "1월~7월까지 10배 증가했으며, 2024년 8월 한 달 동안 가장 사용자 수가 많았던 버전은 ‘라마 3.1-405B’로 \n",
      "최대 규모 AI 모델의 인기를 입증\n",
      "2024년 10월호\n",
      "1월~7월까지 10배 증가했으며, 2024년 8월 한 달 동안 가장 사용자 수가 많았던 버전은 ‘라마 3.1-405B’로 \n",
      "최대 규모 AI 모델의 인기를 입증\n",
      "∙자체 활용 목적에 맞게 라마를 미세 조정하는 개발자 커뮤니티가 활성화되며, 허깅페이스에는 6만 개 \n",
      "이상의 라마 파생 모델이 존재\n",
      "∙메타는 라마의 성공이 오픈소스에 기인한다며, 개발자의 선택권과 역량을 보장함으로써 AI 생태계가 \n",
      "활성화되고 광범위하고 빠른 혁신이 가능해졌다고 강조\n",
      "£ 액센추어, AT&T 등 주요 기업들, 라마를 자체 목적에 맞게 미세 조정해 활용\n",
      "n 메타는 공식 사이트에 라마를 미세 조정해 자체적으로 활용하는 주요 기업의 사례를 소개\n",
      "∙액센추어(Accenture)는 라마 3.1을 사용해 ESG(환경·사회·지배구조) 보고서를 생성하는 맞춤형 \n",
      "LLM을 구축하고 있으며, 기존 작성 방식 대비 생산성은 70%, 품질은 20~30% 향상을 기대\n",
      "∙AT&T는 라마를 미세 조정하여 핵심 트렌드 및 고객 요구사항과 고객 경험 개선의 기회를 파악해 비용 \n",
      "효율적으로 고객 관리를 지원\n",
      "∙배달 대행 플랫폼 도어대시(DoorDash)는 라마를 사용해 내부 지식기반의 복잡한 질문 응답, 코드 \n",
      "베이스 개선 등 소프트웨어 개발자의 일상 업무를 간소화\n",
      "∙일본 금융기업 노무라(Nomura)는 텍스트 요약, 편향 방지, 코드 생성, 로그 분석 등 문서 관련 업무 \n",
      "전반에서 AWS를 통해 라마를 활용\n",
      "∙줌(Zoom)은 자체 모델과 폐쇄형 및 오픈소스 LLM(라마 포함)을 활용해 회의 요약, 스마트 녹음 등\n",
      "* 디지털 콘텐츠에 메타데이터를 포함하여 제작 출처와 관련된 정보를 확인할 수 있게 하는 기술 표준\n",
      "∙‘콘텐츠 자격증명’ 2.1 버전은 콘텐츠 출처 이력을 검증하기 위한 기술적 요구 사항을 강화해 다양한 \n",
      "위변조 공격에 대응한 보안을 향상\n",
      "£ 구글, AI 생성물 출처 확인을 위해 C2PA의 최신 기술 표준을 자사 서비스에 적용 계획\n",
      "n 구글은 향후 몇 달 동안 ‘콘텐츠 자격증명’ 2.1 버전을 검색과 광고 등 주요 서비스에 적용할 계획 \n",
      "∙이미지에 C2PA 메타데이터가 포함된 경우, 이용자들은 구글의 이미지 관련 서비스에서 제공하는 \n",
      "‘About this image’ 기능을 통해 이미지가 AI 도구로 생성 또는 편집되었는지 확인 가능\n",
      "∙구글은 광고 시스템에도 C2PA 메타데이터의 도입을 확대하는 한편, C2PA를 활용해 주요 정책의 \n",
      "시행 방법을 안내할 계획\n",
      "∙구글은 유튜브에서도 C2PA로 제공되는 출처 정보를 사용자에게 전달할 방법을 모색 중으로, 2024년 \n",
      "말 관련 업데이트를 진행 예정\n",
      "∙향후 발표될 ‘C2PA 신뢰 목록(Trust List)’을 통한 콘텐츠 출처 확인도 지원할 계획으로, 가령 \n",
      "이용자들이 특정 카메라 모델로 촬영된 이미지의 경우 신뢰 목록을 통해 해당 출처 정보의 정확성을 검증 가능 \n",
      "n 구글은 온라인 콘텐츠 출처 확인을 위해 더 많은 서비스 및 하드웨어 업체의 C2PA 표준 채택을 \n",
      "촉구하는 한편, 구글 딥마인드(Deepmind)에서 개발한 워터마킹 기술 ‘신스ID(SynthID)’를 여러 \n",
      "AI 도구 및 미디어에 확대 적용함으로써 자체적인 노력도 추진\n"
     ]
    }
   ],
   "source": [
    "for doc in vectorstore.similarity_search(\"메타\"):\n",
    "    print(doc.page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 벡터스토어에 있는 정보를 검색하고 생성\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    You are an assistant for question-answering tasks. \n",
    "    Use the following pieces of retrieved context to answer the question.\n",
    "    Use a very kind and gentle tone like a kindergarten teacher talking to a child.\n",
    "    Speak in a warm and friendly way.\n",
    "    If you don't know the answer, just say that you don't know. \n",
    "    Answer in Korean.\n",
    "\n",
    "    #Context: \n",
    "    {context}\n",
    "\n",
    "    #Question:\n",
    "    {question}\n",
    "\n",
    "    #Answer:\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "chain = (\n",
    "    {\"context\" : retriever, \"question\" : RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "안녕, 친구야! UN에서 발표한 최종 보고서에 대해 이야기해줄게. 이 보고서는 '인류를 위한 AI 거버넌스'라는 주제로 만들어졌어. 보고서에서는 AI의 위험을 해결하고, 그 혁신적인 잠재력을 잘 활용하기 위해 국제 협력을 바탕으로 한 포용적이고 분산된 AI 거버넌스 체계를 마련하자고 촉구했단다. 그리고 AI 국제과학 패널 구성, AI 정책 대화, AI 표준 교류와 AI 역량 개발 네트워크 형성 등 7가지 권고안을 제시했어. 이 모든 것들은 AI가 사람들에게 더 좋은 영향을 미칠 수 있도록 돕기 위한 것이란다. 궁금한 게 더 있으면 언제든지 물어봐!\n"
     ]
    }
   ],
   "source": [
    "# 체인 실행\n",
    "question = \"un에서 발표한 최종보고서 내용 요약해주\"\n",
    "response = chain.invoke(question)\n",
    "\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
